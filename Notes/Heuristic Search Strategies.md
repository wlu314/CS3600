## [[Best-First Search]]
___
This is an instance of the general Tree-Search or Graph-Search algorithm where a node is selected for expansion based on the **evaluation function, $f(n)$**. This function is construed as a cost estimate so the node with the lowest evaluation is expanded first. The implementation is identical to [[Uniform-Cost Search]] except for the use of $f$ instead if $g$ to order the PQ.  

**Heuristic Function, $h(n)$** is the estimated cost of the cheapest path from the state a node n to a gaol state. 

## $A^*$ Search
____
[[A* Search]] evaluates nodes by combining $g(n)$, the cost to reach the node, and $h(n)$, the cost to get from the node to the goal. $f(n)=g(n)+h(n)$. Since $g(n)$ gives the path from the start node to node *n*, and the $h(n)$ is the estimated cost of the cheapest path from *n* to the goal, we have the estimated cost of the cheapest solution through *n*. 

## Heuristic Function
_____
![[Figure 3.28.png]]The 8-puzzle was one of the earliest heuristic search problems. The object of the puzzle is to slide the tiles horizontally or vertically into the empty space until the configuration matches the goal configuration. The **average solution** cost for a randomly generated 8-puzzle instance is about 22 steps. The **[[Branching Factor]]** is 3. When the empty tile is in the middle, four moves are possible; when it's in a corner, two moves, when its along an edge, three moves. The exhaustive tree search to depth 22 would be $3^{22}$ states. 

In order to find the shortest solution using $A^*$ we need a heuristic function that *doesn't overestimate* the number of steps to the goal. There is two commonly used candidate:
1. $h_1$, the number of misplaced tiles. If 8 tiles are out of position, $h_1=8$. This is admissible heuristic because ti is clear that nay tile out of place must be moved at least once. 
2. $h_2$, the num of distances of tiles from their goal position. Because tiles cannot move along diagonals, the distance will count is the sum of horizontal and vertical distance. This is called the **Manhattan Distance**. This is admissible (doesn't overestimate) because all moves can do is move tile. From the tiles 1 to 8, in the start state give a manhattan distance of $h_2=18$. The true solution is 26, such that it doesn't overestimate it. 

#### Heuristic Accuracy on Performance
____
The **effective branching factor**, $b^*$ is the way to characterize the quality of the heuristic. If the total number of nodes generated by $A^*$ for a particular problem $N$ and the solution depth is $d$, then $b^*$ of the uniform tree depth $d$ would have in order to contain $N+1$ nodes. Thus $N+1=1+b^*+(b^*)^2+...+(b^*)^d$. For example, if $A^*$ finds a solution at depth 5 using 52 nodes, then the effective branching factor is 1.92. The number of nodes expanded by $A^*$ grows exponentially with solution depth. It is generally better to use a heuristic function with higher values provided it is consistent and that the computation time for the heuristic is not too long. 
![[Figure 3.29.png]]
**Pattern Databases**: This is the idea is to store the exact solution costs for every possible subproblem instance. 

#### Learning Heuristic From Experience
____
A heuristic function $h(n)$ is supposed to estimate the cost of a solution beginning from the state at node $n$. How could an agent construct such a function? One solution was given in the preceding sections—namely, to devise relaxed problems for which an optimal solution can be found easily. Another solution is to learn from experience. “Experience” here means solving lots of 8-puzzles, for instance. Each optimal solution to an 8-puzzle problem provides examples from which $h(n)$ can be learned. Each example consists of a state from the solution path and the actual cost of the solution from that point. From these examples, a learning algorithm can be used to construct a function $h(n)$ that can (with luck) predict solution costs for other states that arise during search. Techniques for doing just this using neural nets, decision trees, and other methods are demonstrated. 

Inductive learning methods work best when supplied with features of a state that are relevant to predicting the state’s value, rather than with just the raw state description. For example, the feature “number of misplaced tiles” might be helpful in predicting the actual distance of a state from the goal. Let’s call this feature $x_1(n)$. We could take 100 randomly generated 8-puzzle configurations and gather statistics on their actual solution costs. We might find that when $x_1(n)$ is 5, the average solution cost is around 14, and so on. Given these data, the value of $x_1$ can be used to predict $h(n)$. Of course, we can use several features. A second feature $x_2(n)$ might be “number of pairs of adjacent tiles that are not adjacent in the goal state.” How should $x_1(n)$ and $x_2(n)$ be combined to predict $h(n)$? A common approach is to use a linear combination:

$$ h(n) = c_1 x_1(n) + c_2 x_2(n)$$

The constants $c_1$ and  $c_2$ are adjusted to give the best fit to the actual data on solution costs. One expects both $c_1$and $c_2$ to be positive because misplaced tiles and incorrect adjacent pairs make the problem harder to solve. Notice that this heuristic does satisfy the condition that $h(n) = 0$ for goal states, but it is not necessarily admissible or consistent.

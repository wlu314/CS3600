Supervised Learning is a type [[Machine Learning]] technique where the agent observes some example input-output pairs and learns a function that maps from input to output. Inputs are percepts.

# General Task
____
The task of supervised learning is:
- Given a training set of N example input-output pairs $$(x_1,y_1),(x_2,y_2),...(x_N,y_N),$$
- where each $y_j$ was generated by an unknown function $y=f(x)$ discover a function $h$ that approximates the true function $f$
- The function $h$ is a hypothesis. Learning is a search through the space of possible hypotheses for one that will perform well. 
- To measure the **accuracy** of the hypothesis, we give it a **test set** of examples that are distinct from the training set.
![[Figure 18.1.png]]

- The hypothesis **generalizes** well if it correctly predicts the value of $y$ for some novel example. Sometimes the function is stochastic - it is not a function of x. We have to learn the [[Conditional Probability]] distribution $P(Y|x)$
- When the output is one of a finite set of values the learning problem is called **classification** and is called **Binary Classification** if there is only two values.
- When the output is a number, the learning problem is called **regression**.
- Supervised learning can be done by choosing the hypothesis $h^*$ that most probable given the data $$h^*=argmax_{h_\in H} P(h|data)$$or using [[Bayes' Rule]]$$h^*=argmax_{h_\in H} P(data|h)P(h)$$
- The prior probability $P(h)$ is high for a low degree polynomial and lower for a higher degree polynomial.


Chapter 1 - [[Introduction]]
Chapter 2 - [[Intelligent Agents]]
Chapter 3 - [[Solving Problems using Search]]
Chapter 4 - [[Beyond Classical Search]]
Chapter 5 - [[Adversarial Search]]

Chapter 13 
	13.1 - [[Acting Under Uncertainty]]
	13.2 - [[Probability Theory for AI]]
	
Chapter 14
	[[Hidden Markov Models]]
	
Chapter 17 - [[Making Complex Decisions]] 
	17.2 - [[Value Iteration]] 
	17.3 - [[Policy Iteration]]
	17.4 - [[Partially Observable MDPs]]  
	17.5 - [[Game Theory Regarding Multiple Agents]]
Chapter 18 - [[Machine Learning]]
[[Reinforcement Learning]]


## MDPs and RL
Known MDP (observable): offline solution
	Compute $V^*, Q^*, \pi ^*$: [[Value Iteration]] and [[Policy Iteration]]
	Evaluate a fixed policy $\pi$: Policy Evaluation
Unknown MDP: Model-Based
	Compute $V^*, Q^*, \pi ^*$: Value Iteration and Policy Iteration on approximate MDP 
	Evaluate a fixed policy $\pi$: Policy Evaluation
Unknown MDP: Model-Free
	Compute $V^*, Q^*, \pi ^*$: Q-Learning
	Evaluate a fixed policy $\pi$: Value Learning

[[Conditional Probability]]
[[Inference By Enumeration]]
[[The Product Rule]]
[[The Chain Rule]]
[[Bayes' Rule]]
[[Bayes' Net]]
[[Sampling in Bayes' Nets]] 
[[Decision Network]]
[[Markov Models]]
[[Hidden Markov Models]]
[[Naive Bayes']]
[[Linear Models]]
[[Nearest-Neighbor Classification]] 
[[Dual-Form Perceptron]]
[[Clustering]] 
[[Optimizing ML]] 
[[Neural Networks]]
[[Supervised Learning]]
[[Learning Decision Tree]]

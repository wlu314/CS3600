This chapter examines search algorithms for problems beyond the case of finding the shortest path to a goal in an observable, deterministic, discrete environment. 
- [[Local Search]] methods like hill climbing operates on complete state formulations keeping a small number of nodes in memory. [[Simulated Annealing]] is a stochastic algorithm that returns the optimal solutions when given an appropriate cooling. 
- [[Linear Programming]] and [[Convex Optimization]] obey certain restrictions on the shape of the state space and the nature of the objective function, and admit polynomial-time algorithms that are often extremely efficient in practice. 
- [[Courses/CS-3600/Notes/Genetic Programming]] is a **stochastic hill climbing search** which a large population of states is maintained. New states generated by **mutations** and by **crossovers**. 
- In nondeterministic environments, agents can apply AND-OR search to generate contingent plans to reach that goal regardless of which outcomes occur during execution
- When the environment is partially observable, the [[Belief State]] represents the set of possible states that the agent might be in. 
- Standard search algorithms can be applied directly to belief-state space to solve sensor- less problems, and belief-state ANDâ€“OR search can solve general partially observable problems. Incremental algorithms that construct solutions state-by-state within a belief state are often more efficient.
- Exploration problems arise when the agent has no idea about the states and actions of its environment. For safely explorable environments, online search agents can build a map and find a goal if one exists. Updating heuristic estimates from experience provides an effective method to escape from local minima.